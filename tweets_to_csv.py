# -*- coding: utf-8 -*-
"""tweets_to_csv.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HwGTLDltEjb-7-Ev1ekKQbA3UDwPwcFO
"""

# Imports
import snscrape.modules.twitter as sntwitter
import pandas as pd
import re

def clean(text):
  ''' Uses regular expresison to extract english letter and digits from the supplied text. '''
  regExp = "(@[A-Za-z0-9]+)|([^0-9A-Za-z \t])|(\w+:\/\/\S+)"
  return ' '.join(re.sub(regExp, " ", text).split())

def get_tweets(what, since='2022-01-01', until='2022-05-01', maxTweets = 500):
  '''
  Scrape twitter for a serach term between given data.

  what - the search term
  since - the date to start search from
  unitl - the date to search to
  maxTweets - maximun number of tweets to retrun

  Created for ISYS2001 to simplify the data extraction
  '''
  
  # Using TwitterSearchScraper to scrape data and append tweets to list
  query = sntwitter.TwitterSearchScraper(f'{what} since:{since} until:{until}').get_items()
  tweet_data = [next(query) for _ in range(maxTweets)]
  tweets = [[tweet.date, tweet.id, tweet.content] for tweet in tweet_data ]

  # Creating a dataframe from the tweets list above
  tweets_df = pd.DataFrame(tweets, columns=['Datetime', 'Tweet Id', 'Text'])

  # Clean the data
  tweets_df['Clean Text'] = tweets_df['Text'].apply(clean)
  tweets_df['Date'] = pd.to_datetime(tweets_df['Datetime']).dt.date

  # Save Columns interested in 
  tweets_df[['Date','Clean Text']].to_csv("tweets.csv")